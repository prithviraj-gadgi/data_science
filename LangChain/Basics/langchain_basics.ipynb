{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a969344-73cb-4e37-8d53-e18b8b487bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06bfff4-f67d-4fa1-89ba-f52fd789b313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e40eb6-bb19-4e0a-942e-7dd1bf2a9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437dd935-5a8a-46b6-b387-3a50f0ed5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e161a17-55d8-464a-a2d8-8f281b232e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice Palace: A Taste of India\"\n"
     ]
    }
   ],
   "source": [
    "name = llm.invoke('I want to open a restorant for Indian food. Suggest a fancy name for this.')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c070b6-aebf-4fbb-b535-e34f25a4ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b933234-4099-43af-aae0-33601357de3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restorant for Indian food. Suggest a fancy name for this.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    template='I want to open a restorant for {cuisine} food. Suggest a fancy name for this.', \n",
    "    input_variables=['cuisine']\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine='Indian') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28fb78b4-1aa8-4d4b-8c8e-2b7eaf651668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c856efde-9432-4c56-9a82-f49879b2e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\AppData\\Local\\Temp\\ipykernel_12056\\3541426536.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n"
     ]
    }
   ],
   "source": [
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172d85e1-4e7b-4ff2-90e8-7b903ea23a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Chinees', 'text': '\\n\"Golden Dragon Palace\"'}\n"
     ]
    }
   ],
   "source": [
    "name = name_chain.invoke('Chinees')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0937de87-127c-4039-bcd3-a5bab0e7dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = prompt_template_name | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889ccba8-cd43-46df-811f-8c0040dcde8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Imperial Dragon Palace\"\n"
     ]
    }
   ],
   "source": [
    "name = name_chain.invoke('Chinees')\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8abcf24e-9c58-4ad4-b7b7-a1021f66acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    template='I want to open a restorant for {cuisine} food. Suggest a fancy name for this.', \n",
    "    input_variables=['cuisine']\n",
    ")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as a comma separated list.',\n",
    "    input_variables=['restaurant_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56de2713-df6d-4447-a2c7-806f9afef186",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template_name | prompt_template_items | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04d8ea2-d817-4411-a586-7b39e2c93972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tandoori Palace \n",
      "2. Spice Kingdom \n",
      "3. Curry Mansion \n",
      "4. Masala Mansion \n",
      "5. Naan Nook \n",
      "6. Tandoori Terrace \n",
      "7. Saffron Palace \n",
      "8. Chai Chalet \n",
      "9. Biryani Bistro \n",
      "10. Samosa Spot\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Indian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d7bd6f-51e7-4d97-b893-b072017b3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant Name: \n",
      "\n",
      "\"El Sabor de México\" (The Flavor of Mexico) \n",
      "Menu Items: \n",
      "\n",
      "1. Tacos al Pastor\n",
      "2. Enchiladas Verdes\n",
      "3. Carne Asada\n",
      "4. Chiles Rellenos\n",
      "5. Pozole\n",
      "6. Fajitas\n",
      "7. Carnitas\n",
      "8. Quesadillas\n",
      "9. Tamales\n",
      "10. Sopes\n",
      "11. Mole Poblano\n",
      "12. Chimichangas\n",
      "13. Tostadas\n",
      "14. Burritos\n",
      "15. Flautas\n",
      "16. Ceviche\n",
      "17. Chilaquiles\n",
      "18. Tres Leches Cake\n",
      "19. Horchata\n",
      "20. Margaritas\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# Prompt to generate restaurant name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    template='I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.',\n",
    "    input_variables=['cuisine']\n",
    ")\n",
    "\n",
    "# Prompt to generate menu items\n",
    "prompt_template_items = PromptTemplate(\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as a comma separated list.',\n",
    "    input_variables=['restaurant_name']\n",
    ")\n",
    "\n",
    "# Chain 1: cuisine -> restaurant_name\n",
    "name_chain = RunnableMap({\n",
    "    \"restaurant_name\": prompt_template_name | llm\n",
    "})\n",
    "\n",
    "# Custom chain to keep restaurant_name and generate menu_items\n",
    "def generate_menu_with_name(inputs):\n",
    "    restaurant_name = inputs[\"restaurant_name\"]\n",
    "    menu_items = (prompt_template_items | llm).invoke({\"restaurant_name\": restaurant_name})\n",
    "    return {\n",
    "        \"restaurant_name\": restaurant_name,\n",
    "        \"menu_items\": menu_items\n",
    "    }\n",
    "\n",
    "# Full chain: cuisine -> restaurant_name -> menu_items\n",
    "full_chain = name_chain | RunnableLambda(generate_menu_with_name)\n",
    "\n",
    "# Invoke chain\n",
    "result = full_chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "print(\"Restaurant Name:\", result[\"restaurant_name\"])\n",
    "print(\"Menu Items:\", result[\"menu_items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa3ff9f3-8674-44eb-acda-db1429859587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b959a4-4a19-455e-8e1f-69f661c8d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a11903d-9462-44ff-a929-7818c81926c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bf4307d-2387-45ef-895f-237db6bbc9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    template='I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.',\n",
    "    input_variables=['cuisine']\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca8983a-2a22-4b91-8cbd-e6a32cc434af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    template='Suggest some menu items for {restaurant_name}. Return it as a comma separated list.',\n",
    "    input_variables=['restaurant_name']\n",
    ")\n",
    "\n",
    "menu_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='menu_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c648c2-c0cf-48d9-8055-92cbcaf7db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'restaurant_name': '\\n\"El Jardín de Sabores\" (The Garden of Flavors)', 'menu_items': '\\n\\n1. Ensalada de Jardín (Garden Salad)\\n2. Fajitas de Pollo con Verduras (Chicken Fajitas with Vegetables)\\n3. Filete de Pescado al Limón (Lemon Fish Fillet)\\n4. Tacos de Carne Asada (Grilled Steak Tacos)\\n5. Arroz con Camarones (Shrimp and Rice)\\n6. Quesadillas de Hongos (Mushroom Quesadillas)\\n7. Sopa de Tortilla (Tortilla Soup)\\n8. Enchiladas de Queso (Cheese Enchiladas)\\n9. Tamales de Pollo (Chicken Tamales)\\n10. Burrito de Vegetales (Vegetable Burrito)\\n11. Flautas de Res (Beef Flautas)\\n12. Tostadas de Ceviche (Ceviche Tostadas)\\n13. Chiles Rellenos (Stuffed Peppers)\\n14. Guacamole y Chips (Guacamole and Chips)\\n15. Tres Leches Cake (Three Milk Cake)\\n16. Churros con Chocolate (Churros with Chocolate Sauce)'}\n",
      "Restaurant Name: \n",
      "\"El Jardín de Sabores\" (The Garden of Flavors)\n",
      "Menu Items: \n",
      "\n",
      "1. Ensalada de Jardín (Garden Salad)\n",
      "2. Fajitas de Pollo con Verduras (Chicken Fajitas with Vegetables)\n",
      "3. Filete de Pescado al Limón (Lemon Fish Fillet)\n",
      "4. Tacos de Carne Asada (Grilled Steak Tacos)\n",
      "5. Arroz con Camarones (Shrimp and Rice)\n",
      "6. Quesadillas de Hongos (Mushroom Quesadillas)\n",
      "7. Sopa de Tortilla (Tortilla Soup)\n",
      "8. Enchiladas de Queso (Cheese Enchiladas)\n",
      "9. Tamales de Pollo (Chicken Tamales)\n",
      "10. Burrito de Vegetales (Vegetable Burrito)\n",
      "11. Flautas de Res (Beef Flautas)\n",
      "12. Tostadas de Ceviche (Ceviche Tostadas)\n",
      "13. Chiles Rellenos (Stuffed Peppers)\n",
      "14. Guacamole y Chips (Guacamole and Chips)\n",
      "15. Tres Leches Cake (Three Milk Cake)\n",
      "16. Churros con Chocolate (Churros with Chocolate Sauce)\n"
     ]
    }
   ],
   "source": [
    "chain = SequentialChain(\n",
    "    chains = [name_chain, menu_chain], \n",
    "    input_variables=['cuisine'], \n",
    "    output_variables=['restaurant_name', 'menu_items']\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "print(result)\n",
    "print(\"Restaurant Name:\", result[\"restaurant_name\"])\n",
    "print(\"Menu Items:\", result[\"menu_items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cab5c9d-3469-431e-97e1-14875af2391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant Name: \n",
      "\n",
      "\"El Jardín de Sabores\" (The Garden of Flavors)\n",
      "Menu Items:       \n",
      "\n",
      "1. Ensalada de Quinoa (Quinoa Salad)\n",
      "2. Tacos de Pescado (Fish Tacos)\n",
      "3. Pollo al Horno con Hierbas (Herb Roasted Chicken)\n",
      "4. Arroz con Frijoles (Rice and Beans)\n",
      "5. Sopa de Tortilla (Tortilla Soup)\n",
      "6. Enchiladas Verdes (Green Enchiladas)\n",
      "7. Chiles Rellenos (Stuffed Peppers)\n",
      "8. Carne Asada (Grilled Steak)\n",
      "9. Camarones al Ajillo (Garlic Shrimp)\n",
      "10. Fajitas de Vegetales (Vegetable Fajitas)\n",
      "11. Tamales de Pollo (Chicken Tamales)\n",
      "12. Flan de Caramelo (Caramel Flan)\n",
      "13. Horchata (Rice Milk Drink)\n",
      "14. Margaritas (Traditional Mexican Cocktail)\n",
      "15. Tres Leches Cake (Milk Soaked Cake)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
    "\n",
    "# 1) Initialize your LLM\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# 2) Build a map that, given `cuisine`, returns `restaurant_name`\n",
    "prompt_name = PromptTemplate(\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\",\n",
    "    input_variables=[\"cuisine\"]\n",
    ")\n",
    "name_chain = RunnableMap({\"restaurant_name\": prompt_name | llm})\n",
    "\n",
    "# 3) Build a map that, given `restaurant_name`, returns `menu_items`\n",
    "prompt_menu = PromptTemplate(\n",
    "    template=\"Suggest some menu items for {restaurant_name}. Return it as a comma separated list.\",\n",
    "    input_variables=[\"restaurant_name\"]\n",
    ")\n",
    "menu_chain = RunnableMap({\"menu_items\": prompt_menu | llm})\n",
    "\n",
    "# 4) Wrap both steps in a single RunnableLambda that merges their outputs\n",
    "def two_step(inputs: dict) -> dict:\n",
    "    # run the first chain\n",
    "    name_out = name_chain.invoke(inputs)\n",
    "    # run the second chain using the first's result\n",
    "    menu_out = menu_chain.invoke(name_out)\n",
    "    # merge both dictionaries into one\n",
    "    return {**name_out, **menu_out}\n",
    "\n",
    "full_chain = RunnableLambda(two_step)\n",
    "\n",
    "# 5) Invoke with your initial input\n",
    "result = full_chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "\n",
    "# 6) Print both pieces cleanly\n",
    "print(\"Restaurant Name:\", result[\"restaurant_name\"])\n",
    "print(\"Menu Items:      \", result[\"menu_items\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2753892-5498-4027-8bf6-988cb460ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:    \n",
      "\n",
      "\"La Casa de Sabor\" (The House of Flavor)\n",
      "Menu:    \n",
      "\n",
      "1. Arroz con pollo (rice with chicken)\n",
      "2. Ropa vieja (shredded beef stew)\n",
      "3. Picadillo (ground beef with vegetables)\n",
      "4. Lechón asado (roast pork)\n",
      "5. Tostones (fried plantains)\n",
      "6. Empanadas (stuffed pastries)\n",
      "7. Paella (Spanish-style rice with seafood and meats)\n",
      "8. Tamales (corn dough filled with meat and steamed in banana leaves)\n",
      "9. Mofongo (mashed plantains with garlic and pork cracklings)\n",
      "10. Churrasco (grilled steak)\n",
      "11. Camarones al ajillo (garlic shrimp)\n",
      "12. Pernil (slow-roasted pork shoulder)\n",
      "13. Flan (caramel custard)\n",
      "14. Tres leches cake (sponge cake soaked in three types of milk)\n",
      "15. Moros y cristianos (black beans and rice)\n",
      "Tagline: \n",
      "\n",
      "\"Where every bite feels like home.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# Chain A: cooks up a restaurant name\n",
    "name_chain = RunnableMap({\n",
    "    \"restaurant_name\": PromptTemplate(\n",
    "        template=\"Suggest a fancy name for a {cuisine} restaurant.\",\n",
    "        input_variables=[\"cuisine\"]\n",
    "    ) | llm\n",
    "})\n",
    "\n",
    "# Chain B: generates menu items\n",
    "menu_chain = RunnableMap({\n",
    "    \"menu_items\": PromptTemplate(\n",
    "        template=\"List some signature dishes for '{restaurant_name}'.\",\n",
    "        input_variables=[\"restaurant_name\"]\n",
    "    ) | llm\n",
    "})\n",
    "\n",
    "# Chain C: writes a short tagline\n",
    "tagline_chain = RunnableMap({\n",
    "    \"tagline\": PromptTemplate(\n",
    "        template=\"Write a catchy tagline for a restaurant named '{restaurant_name}'.\",\n",
    "        input_variables=[\"restaurant_name\"]\n",
    "    ) | llm\n",
    "})\n",
    "\n",
    "# Wrap all three in one RunnableLambda\n",
    "def multi_step(inputs: dict) -> dict:\n",
    "    # 1) name\n",
    "    out1 = name_chain.invoke(inputs)\n",
    "    # 2) menu (needs restaurant_name)\n",
    "    out2 = menu_chain.invoke(out1)\n",
    "    # 3) tagline (also needs restaurant_name)\n",
    "    out3 = tagline_chain.invoke(out1)\n",
    "    # merge all results\n",
    "    return {**out1, **out2, **out3}\n",
    "\n",
    "full_chain = RunnableLambda(multi_step)\n",
    "\n",
    "# Invoke with just the cuisine\n",
    "result = full_chain.invoke({\"cuisine\": \"Mexican\"})\n",
    "print(\"Name:   \", result[\"restaurant_name\"])\n",
    "print(\"Menu:   \", result[\"menu_items\"])\n",
    "print(\"Tagline:\", result[\"tagline\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7742ff0-be2c-4526-8e3b-b8a026c3417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, load_tools, initialize_agent\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629648d3-8daf-45f7-8b55-5ca018c884d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0448a44e-5ab2-4041-8980-0fa3e9ff2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(tool_names=['wikipedia', 'llm-math'], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ba3b33-8ea6-4ecd-9c6e-b301333ff56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\AppData\\Local\\Temp\\ipykernel_15248\\494517627.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c8ca2b-a993-4cd4-95ad-609130fdde1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'When was Elon Musk born? What is his age right now?',\n",
       " 'output': 'Elon Musk is currently 50 years old.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke('When was Elon Musk born? What is his age right now?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9d5de1-9eff-497d-b50f-e5e8a062f6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9915db6-ad05-4ba3-86eb-8fe9ecbf0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c74bfc-fc71-4f33-895b-4b08460f1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(tool_names=['serpapi', 'llm-math'], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d4f94a2-b46e-48d7-b50a-04bfa56807b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "750c06ef-f567-4bd9-b65b-c4f76a7c6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US in 2014\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Current-dollar GDP increased 3.9 percent, or $652.6 billion, in 2014 to a level of $17,420.7 billion, compared with an increase of 3.7 percent, ...', '2014, $17.608T ; 2013, $16.881T ; 2012, $16.254T ; 2011, $15.600T.', 'In 2024, the U.S. GDP increased from the previous year to about 29.18 trillion U.S. dollars. ... 2014 2016 2018 2020 2022 2024. 05,00010,00015,000 ...', 'GDP growth (annual %) - United States. World Bank national accounts data, and OECD National Accounts data files.', \"The GDP figure in 2014 was €13,250,719$17,608,100 million, United States is the world's leading economy with regard to GDP, as can be seen in the ranking of GDP ...\", 'Gross domestic product (GDP), the featured measure of U.S. output, is the ... 17518.508. 2014-07-01, 17804.228. 2014-10-01, 17912.079. 2015-01-01, 18063.529.', 'With an estimated $2.31 trillion of GDP in 2014, California has the largest state-level economy in the U.S. due largely to its population, which ...', 'U.S. GDP Growth Rate. Population Economy Trade Health Education Development ... 2014, 0.4%. 2013, -0.17%. 2012, 0.73%. 2011, -1.14%. 2010, 5.28%. 2009, -2.69%.', 'The \"second\" estimate of the fourth-quarter percent change in GDP is 0.4 percentage point, or $17.9 billion, less than the advance estimate issued last month.', 'Gross Domestic Product (GDP) of the United States ; 2014, $17,608,100,000,000, $17,771,500,000,000 ; 2013, $16,880,700,000,000, $17,334,100,000,000 ; 2012 ...']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to find the final answer.\n",
      "Action: Calculator\n",
      "Action Input: 17,608,100,000,000 + 17,771,500,000,000 + 16,880,700,000,000 + 17,334,100,000,000\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 69594400000000\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The GDP of US in 2014 was $69,594,400,000,000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the GDP of US in 2014?',\n",
       " 'output': 'The GDP of US in 2014 was $69,594,400,000,000.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke('What was the GDP of US in 2014?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9d0a37-a2ba-4216-bae9-b9b639da0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7f363fb-7059-49a5-a72a-8f443f3d6c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\AppData\\Local\\Temp\\ipykernel_15248\\3135384584.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3efc1b21-f4a8-40d9-9467-c5887fb92e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\AppData\\Local\\Temp\\ipykernel_15248\\3140875318.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=OpenAI(temperature=0.7), memory=memory)\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=OpenAI(temperature=0.7), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "063b1367-e68b-4eac-ac7d-686eabd4cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricker world cup?',\n",
       " 'history': '',\n",
       " 'response': ' The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was held in England and was organized by the International Cricket Council. Do you follow cricket?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke('Who won the first cricker world cup?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbb6e915-142f-4b6e-8ce7-ca58b3171167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 5+5?',\n",
       " 'history': 'Human: Who won the first cricker world cup?\\nAI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was held in England and was organized by the International Cricket Council. Do you follow cricket?',\n",
       " 'response': ' 10'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke('what is 5+5?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28a2b446-1c95-4ddb-8e6c-75a3006acf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'who was the captain of the winning team?',\n",
       " 'history': 'Human: what is 5+5?\\nAI:  10',\n",
       " 'response': ' I do not have enough context to accurately answer that question. Can you provide me with more information?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke('who was the captain of the winning team?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec4f75-dc10-4ddc-9807-fff745d73fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
